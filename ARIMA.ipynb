{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ARIMA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "KoXNbeZDmv7Q"
      },
      "outputs": [],
      "source": [
        "#@title ARIMA\n",
        "import statsmodels.tsa.api as tsa\n",
        "import numpy as np\n",
        "from patsy import dmatrices\n",
        "from numpy import hstack\n",
        "from numpy import sum\n",
        "\n",
        "np.random.seed(1)\n",
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from numpy import array\n",
        "from sklearn import preprocessing\n",
        "from pandas import DataFrame, Series\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from numpy import concatenate\n",
        "from scipy.stats import boxcox\n",
        "from math import exp\n",
        "from math import log\n",
        "from numpy import mean\n",
        "import copy\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import statsmodels.api as sm\n",
        "from pandas import concat\n",
        "from math import exp\n",
        "from math import log\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from numpy import array\n",
        "import pickle\n",
        "# %matplotlib inline\n",
        "\n",
        "!pip install pmdarima\n",
        "from pandas.plotting import lag_plot\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pmdarima as pm\n",
        "from pmdarima.arima import auto_arima\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# invert a boxcox transform for one value\n",
        "def invert_boxcox(value, lam):\n",
        "    # log case\n",
        "    if lam == 0:\n",
        "        return exp(value)\n",
        "    # all other cases\n",
        "    return exp(log(lam * value + 1) / lam)\n",
        "\n",
        "#Load county data\n",
        "mydata = pd.read_csv('nas.csv', header=0)\n",
        "dataIn = mydata[mydata.columns[1:8]] \n",
        "dateT = mydata[mydata.columns[0]]\n",
        "dateT = DataFrame(dateT)\n",
        "dateT['dateTime'] = dateT\n",
        "dateT.drop('Unnamed: 0', axis = 1, inplace = True)\n",
        "df_data = pd.concat((dateT, dataIn), axis=1)\n",
        "df_data = df_data.drop(df_data.columns[0], axis = 1)\n",
        "\n",
        "# Drop rows which contain any NaN values in all columns\n",
        "df_data = df_data.dropna( how='all')\n",
        "\n",
        "# Interpolate missing values\n",
        "df_data = df_data.interpolate(method ='linear', limit_direction ='both', limit = 10000, axis=0)\n",
        "\n",
        "# move target variable to the last column to align with surpervise learning struture\n",
        "finData = pd.DataFrame(df_data,columns=['Temp','Preci','Gust','Wind','Windir','LAI','Total Outages'])\n",
        "\n",
        "# Compute an auto-correlation plots\n",
        "X = pm.acf(finData['Total Outages'])\n",
        "# Plot an auto-correlation:\n",
        "pm.plot_acf(X)\n",
        "pm.plot_pacf(X)\n",
        "\n",
        "# Check for stionarity\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from numpy import log\n",
        "result = adfuller(finData['Total Outages'])\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "\n",
        "# Split into train and test set\n",
        "train_size = int(len(finData) * 0.80)\n",
        "train_data, test_data = finData.iloc[0:train_size], finData.iloc[train_size:]\n",
        "\n",
        "# Create input/output samples for estimation of model parameters\n",
        "x_train,y_train = train_data.iloc[:,:-1],train_data.iloc[:,-1]\n",
        "x_test,y_test = test_data.iloc[:,:-1],test_data.iloc[:,-1]\n",
        "\n",
        "# BoxCox Power Transform on train data \n",
        "box_power_train = y_train\n",
        "transformed_train, lmbda = boxcox(box_power_train)\n",
        "df_trans_train = np.array(transformed_train)\n",
        "y_trans_train = df_trans_train.reshape(-1,1)\n",
        "\n",
        "# Apply lamda to test data\n",
        "box_power_test = y_test\n",
        "transformed_test = boxcox(box_power_test,lmbda)  \n",
        "df_trans_test = np.array(transformed_test)\n",
        "y_trans_test = df_trans_test.reshape(-1,1)\n",
        "\n",
        "# 6 Rolling Mean on train data \n",
        "dwAvg = 6\n",
        "y_train_mean = pd.DataFrame(y_trans_train)\n",
        "y_train_mean = y_train_mean.rolling(dwAvg).mean()\n",
        "y_train_mean = y_train_mean.interpolate(method ='linear', limit_direction ='both', limit = 100, axis=0)\n",
        "\n",
        "# Test fold            \n",
        "y_test_mean = pd.DataFrame(y_trans_test)\n",
        "y_test_mean = y_test_mean.rolling(dwAvg).mean()\n",
        "y_test_mean = y_test_mean.interpolate(method ='linear', limit_direction ='both', limit = 100, axis=0)\n",
        "\n",
        "# Scaling\n",
        "# Train\n",
        "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train_scaled_data = X_scaler.fit_transform(x_train)\n",
        "Y_train_scaled_data = Y_scaler.fit_transform(y_train_mean)\n",
        "# Test\n",
        "X_test_scaled_data = X_scaler.transform(x_test)\n",
        "Y_test_scaled_data = Y_scaler.transform(y_test_mean)\n",
        "\n",
        "# Estimate hyper-parameters on raw train data\n",
        "auto_n = auto_arima(Y_train_scaled_data,suppress_warnings=True,seasonal=True,\n",
        "                     stepwise=True,error_action=\"ignore\", max_p=5,maxiter=10,method='nm',\n",
        "                     max_order=None, trace=True,stationary=True)\n",
        "print(auto_n.summary())\n",
        "\n",
        "import pickle\n",
        "# Save model and list objects\n",
        "with open('source_file','wb') as f:\n",
        "    pickle.dump(auto_n,f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load saved objects\n",
        "with open('source_file','rb') as f:\n",
        "    mp = pickle.load(f)\n",
        "\n",
        "# Prepare test data\n",
        "start = 0\n",
        "lag = 6 # look back\n",
        "h = 6   # forecast horizon\n",
        "\n",
        "y_te_input= list()\n",
        "y_te_output= list()\n",
        "predictions = list()\n",
        "\n",
        "y_target = Y_test_scaled_data\n",
        "y_target_value = y_target\n",
        "\n",
        "\n",
        "# Update model and make forecast\n",
        "end = None\n",
        "start = start + lag\n",
        "if end is None:\n",
        "    end = len(y_test) - h\n",
        "for j in range(start, end, lag): \n",
        "    indices_j = range(j-lag, j)\n",
        "    y_tes_input = y_target_value[indices_j]     \n",
        "    mp.update(y_tes_input)    \n",
        "    indicey_j = range(j+1, j+1+h)\n",
        "    y_tes_output = y_target_value[indicey_j]     \n",
        "    y_te_output.append(y_tes_output[-1])   \n",
        "    new_preds, new_conf_int = mp.predict(n_periods=len(y_tes_output),return_conf_int=True)\n",
        "    predictions.append(new_preds[-1])\n",
        "\n",
        "# Compute test scores\n",
        "yhat = np.array(predictions)\n",
        "y_last_h = yhat.reshape(-1,1)\n",
        "# Inverse scale of forecast values\n",
        "pred_Inverse = Y_scaler.inverse_transform(y_last_h)\n",
        "# Inverse power transform of forecast values\n",
        "y_b_inv = [invert_boxcox(x, lmbda) for x in pred_Inverse]\n",
        "y_b_inv = np.array(y_b_inv)\n",
        "\n",
        "y_ac = np.array(y_te_output)\n",
        "y_actual = y_ac.reshape(-1,1)\n",
        "# Inverse scale of actual values\n",
        "actual_Inverse = Y_scaler.inverse_transform(y_actual)\n",
        "# Inverse power transform of actual values\n",
        "y_actual_inv = [invert_boxcox(x, lmbda) for x in actual_Inverse]\n",
        "y_actual_inv = np.array(y_actual_inv)\n",
        "\n",
        "pred = y_b_inv\n",
        "actual = y_actual_inv\n",
        "\n",
        "mse = mean_squared_error(actual, pred)\n",
        "# calculate rmse\n",
        "rmse = sqrt(mse)  \n",
        "# print rmse\n",
        "print('Average Test RMSE: %.3f' % (rmse))\n",
        "\n",
        "# Visualizations\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 8))\n",
        "fig.tight_layout(pad=6.0)\n",
        "\n",
        "axes[0].set_title(\"Actual & forecasted test samples\")\n",
        "axes[0].set_xlabel(\"Time Step\")\n",
        "axes[0].set_ylabel(\"Customer Outages\")\n",
        "\n",
        "real = DataFrame(actual)\n",
        "real = real.values\n",
        "\n",
        "x_axis = np.arange(train_data.shape[0] + pred.shape[0])\n",
        "axes[0].plot(x_axis[:train_data.shape[0]], train_data, alpha=0.75,label='Train Data')\n",
        "axes[0].legend(loc=\"upper right\")\n",
        "axes[0].scatter(x_axis[train_data.shape[0]:], pred, alpha=0.4, marker='o',label='Forecast')\n",
        "axes[0].legend(loc=\"upper right\")\n",
        "axes[0].scatter(x_axis[train_data.shape[0]:], actual, alpha=0.4, marker='x',label='Test Data')\n",
        "axes[0].legend(loc=\"upper right\")\n",
        ")\n",
        "new_x_axis = np.arange(len(actual))\n",
        "axes[1].plot(new_x_axis[:300], real[:300], alpha=0.75,label='Actual',color='blue')\n",
        "axes[1].legend(loc=\"upper right\")\n",
        "axes[1].plot(new_x_axis[:300], pred[:300], alpha=0.75,label='Predicted',color='red')\n",
        "axes[1].legend(loc=\"upper right\")\n",
        "axes[1].set_title(\"Actual & forecasted test samples:First 300 time steps in expanded view\")\n",
        "axes[1].set_xlabel(\"Time Step\")\n",
        "axes[1].set_ylabel(\"Customer Outages\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AR9RPlJFB7h6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}